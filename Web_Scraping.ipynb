#!/usr/bin/env python
# coding: utf-8

# In[1]:


import nltk
import urllib
import bs4 as bs
import re
from nltk.corpus import stopwords
nltk.download('stopwords')


# In[4]:


source = urllib.request.urlopen('https://en.wikipedia.org/wiki/Climate_change').read()
soup = bs.BeautifulSoup(source,'lxml')
text=""


# In[5]:


for paragraph in soup.find_all('p'):
    text += paragraph.text


# In[6]:


text


# In[7]:


#Cleaning the text
text = re.sub(r'\[[0-9]*\]',' ',text)
text = re.sub(r'\s+',' ',text)
text = text.lower()
text = re.sub(r'\d',' ',text)


# In[8]:


text


# In[10]:


import nltk
nltk.download('punkt')
sentences = nltk.sent_tokenize(text)
sentences = [nltk.word_tokenize(i) for i in sentences]


# In[11]:


sentences


# In[ ]:




